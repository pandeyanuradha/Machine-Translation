{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-21eafa2d9464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRepeatVector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"hin.txt\")\n",
    "data = to_lines(data)\n",
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[data[i][:2] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Wow!', 'वाह!'],\n",
       "       ['Help!', 'बचाओ!'],\n",
       "       ['Jump.', 'उछलो.'],\n",
       "       ['Jump.', 'कूदो.'],\n",
       "       ['Jump.', 'छलांग.'],\n",
       "       ['Hello!', 'नमस्ते।'],\n",
       "       ['Hello!', 'नमस्कार।'],\n",
       "       ['Cheers!', 'वाह-वाह!'],\n",
       "       ['Cheers!', 'चियर्स!'],\n",
       "       ['Got it?', 'समझे कि नहीं?']], dtype='<U121')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2774, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Wow!', 'Help!', 'Jump.', ...,\n",
       "       'Democracy is the worst form of government, except all the others that have been tried.',\n",
       "       'If my boy had not been killed in the traffic accident, he would be a college student now.',\n",
       "       \"When I was a kid, touching bugs didn't bother me a bit. Now I can hardly stand looking at pictures of them.\"],\n",
       "      dtype='<U121')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['वाह!', 'बचाओ!', 'उछलो.', ...,\n",
       "       'लोकतंत्र सरकार का सबसे घिनौना रूप है, अगर बाकी सारी तरह की सरकारों को अंदेखा किया जाए तो।',\n",
       "       'अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया होता, तो वह अभी कॉलेज जा रहा होता।',\n",
       "       'जब मैं बच्चा था, मुझे कीड़ों को छूने से कोई परेशानी नहीं होती थी, पर अब मैं उनकी तस्वीरें देखना भी बर्दाश्त नहीं कर सकता।'],\n",
       "      dtype='<U121')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in df[:,0]]\n",
    "df[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in df[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Wow', 'वाह'],\n",
       "       ['Help', 'बचाओ'],\n",
       "       ['Jump', 'उछलो'],\n",
       "       ['Jump', 'कूदो'],\n",
       "       ['Jump', 'छलांग'],\n",
       "       ['Hello', 'नमस्ते।'],\n",
       "       ['Hello', 'नमस्कार।'],\n",
       "       ['Cheers', 'वाहवाह'],\n",
       "       ['Cheers', 'चियर्स'],\n",
       "       ['Got it', 'समझे कि नहीं']], dtype='<U121')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[i,0] = df[i,0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['wow', 'वाह'],\n",
       "       ['help', 'बचाओ'],\n",
       "       ['jump', 'उछलो'],\n",
       "       ['jump', 'कूदो'],\n",
       "       ['jump', 'छलांग'],\n",
       "       ['hello', 'नमस्ते।'],\n",
       "       ['hello', 'नमस्कार।'],\n",
       "       ['cheers', 'वाहवाह'],\n",
       "       ['cheers', 'चियर्स'],\n",
       "       ['got it', 'समझे कि नहीं']], dtype='<U121')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "engl = []\n",
    "hindi = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in df[:,0]:\n",
    "      engl.append(len(i.split()))\n",
    "\n",
    "for i in df[:,1]:\n",
    "      hindi.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':engl, 'hin':hindi})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>hin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2774 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      eng  hin\n",
       "0       1    1\n",
       "1       1    1\n",
       "2       1    1\n",
       "3       1    1\n",
       "4       1    1\n",
       "...   ...  ...\n",
       "2769   17   16\n",
       "2770   14   13\n",
       "2771   15   18\n",
       "2772   18   17\n",
       "2773   22   25\n",
       "\n",
       "[2774 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 2370\n"
     ]
    }
   ],
   "source": [
    "eng_tokenizer = tokenization(df[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 22\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi Vocabulary Size: 2980\n"
     ]
    }
   ],
   "source": [
    "hindi_tokenizer = tokenization(df[:, 1])\n",
    "hindi_vocab_size = len(hindi_tokenizer.word_index) + 1\n",
    "\n",
    "hindi_length = 22\n",
    "print('Hindi Vocabulary Size: %d' % hindi_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,val = train_test_split(df, test_size=0.2, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['theres no use trying to persuade him',\n",
       "        'उसको मनाने की कोशिश करने में कोई फ़ायदा नहीं है।'],\n",
       "       ['i advise you not to borrow money from your friends',\n",
       "        'मेरी तुम्हारे लिए यह सलाह है कि अपने दोस्तों से पैसे उधार मत लो।'],\n",
       "       ['they live in a little village in england',\n",
       "        'वे इंग्लैंड के एक छोटे से गाँव में रहते हैं।'],\n",
       "       ...,\n",
       "       ['he is always complaining about his boss',\n",
       "        'वह हमेशा अपने बॉस की शिकायत करता रहता है।'],\n",
       "       ['because of his advice i was able to succeed',\n",
       "        'मैं उसकी सलाह की वजह से कामयाब हो गया।'],\n",
       "       ['when will you be back it all depends on the weather',\n",
       "        'कब वापस आओगे यह तो मौसम देख कर पता चलेगा।']], dtype='<U121')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "train_y = encode_sequences(hindi_tokenizer, hindi_length, train[:, 1])\n",
    "\n",
    "val_X = encode_sequences(eng_tokenizer, eng_length, val[:, 0])\n",
    "val_y = encode_sequences(hindi_tokenizer, hindi_length, val[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 22)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2219, 22)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 22)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2219, 22)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(eng_vocab_size, hindi_vocab_size, eng_length, hindi_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.3777\n",
      "Epoch 00001: val_loss improved from inf to 2.66181, saving model to model.final\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 79s 20s/step - loss: 6.3777 - val_loss: 2.6618\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.5632\n",
      "Epoch 00002: val_loss improved from 2.66181 to 2.50967, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 80s 20s/step - loss: 2.5632 - val_loss: 2.5097\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.4802\n",
      "Epoch 00003: val_loss improved from 2.50967 to 2.39035, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 74s 18s/step - loss: 2.4802 - val_loss: 2.3903\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.4430\n",
      "Epoch 00004: val_loss did not improve from 2.39035\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.4430 - val_loss: 2.4906\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.4036\n",
      "Epoch 00005: val_loss did not improve from 2.39035\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.4036 - val_loss: 2.4245\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.3111\n",
      "Epoch 00006: val_loss did not improve from 2.39035\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.3111 - val_loss: 2.4057\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.3115\n",
      "Epoch 00007: val_loss improved from 2.39035 to 2.25789, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 73s 18s/step - loss: 2.3115 - val_loss: 2.2579\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.4348\n",
      "Epoch 00008: val_loss did not improve from 2.25789\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4348 - val_loss: 2.4181\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2625\n",
      "Epoch 00009: val_loss did not improve from 2.25789\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.2625 - val_loss: 2.3333\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2199\n",
      "Epoch 00010: val_loss did not improve from 2.25789\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.2199 - val_loss: 2.2618\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1068\n",
      "Epoch 00011: val_loss improved from 2.25789 to 2.23413, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 78s 19s/step - loss: 2.1068 - val_loss: 2.2341\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2641\n",
      "Epoch 00012: val_loss did not improve from 2.23413\n",
      "4/4 [==============================] - 19s 5s/step - loss: 2.2641 - val_loss: 2.2830\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0837\n",
      "Epoch 00013: val_loss improved from 2.23413 to 2.22698, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 92s 23s/step - loss: 2.0837 - val_loss: 2.2270\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1118\n",
      "Epoch 00014: val_loss did not improve from 2.22698\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.1118 - val_loss: 2.2879\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1021\n",
      "Epoch 00015: val_loss did not improve from 2.22698\n",
      "4/4 [==============================] - 18s 4s/step - loss: 2.1021 - val_loss: 2.2573\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0756\n",
      "Epoch 00016: val_loss did not improve from 2.22698\n",
      "4/4 [==============================] - 19s 5s/step - loss: 2.0756 - val_loss: 2.3536\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0497\n",
      "Epoch 00017: val_loss did not improve from 2.22698\n",
      "4/4 [==============================] - 18s 5s/step - loss: 2.0497 - val_loss: 2.2489\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0880\n",
      "Epoch 00018: val_loss improved from 2.22698 to 2.21673, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 81s 20s/step - loss: 2.0880 - val_loss: 2.2167\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9869\n",
      "Epoch 00019: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.9869 - val_loss: 2.3917\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0632\n",
      "Epoch 00020: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 4s/step - loss: 2.0632 - val_loss: 2.2648\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0254\n",
      "Epoch 00021: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 4s/step - loss: 2.0254 - val_loss: 2.2779\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9990\n",
      "Epoch 00022: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.9990 - val_loss: 2.2542\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9859\n",
      "Epoch 00023: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.9859 - val_loss: 2.2863\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9643\n",
      "Epoch 00024: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.9643 - val_loss: 2.3156\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9650\n",
      "Epoch 00025: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.9650 - val_loss: 2.2853\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9505\n",
      "Epoch 00026: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.9505 - val_loss: 2.2755\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9486\n",
      "Epoch 00027: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.9486 - val_loss: 2.2732\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9088\n",
      "Epoch 00028: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.9088 - val_loss: 2.2864\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9196\n",
      "Epoch 00029: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.9196 - val_loss: 2.2564\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9309\n",
      "Epoch 00030: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.9309 - val_loss: 2.2514\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8589\n",
      "Epoch 00031: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.8589 - val_loss: 2.2415\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9315\n",
      "Epoch 00032: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.9315 - val_loss: 2.2479\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8507\n",
      "Epoch 00033: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.8507 - val_loss: 2.2792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8826\n",
      "Epoch 00034: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.8826 - val_loss: 2.2777\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8425\n",
      "Epoch 00035: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.8425 - val_loss: 2.2979\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8677\n",
      "Epoch 00036: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.8677 - val_loss: 2.2777\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8432\n",
      "Epoch 00037: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 21s 5s/step - loss: 1.8432 - val_loss: 2.2639\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8362\n",
      "Epoch 00038: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 21s 5s/step - loss: 1.8362 - val_loss: 2.2682\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8011\n",
      "Epoch 00039: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.8011 - val_loss: 2.2877\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8567\n",
      "Epoch 00040: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.8567 - val_loss: 2.2719\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7787\n",
      "Epoch 00041: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.7787 - val_loss: 2.2919\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8196\n",
      "Epoch 00042: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.8196 - val_loss: 2.2734\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7710\n",
      "Epoch 00043: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.7710 - val_loss: 2.2893\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7898\n",
      "Epoch 00044: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.7898 - val_loss: 2.2971\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7527\n",
      "Epoch 00045: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.7527 - val_loss: 2.2802\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7711\n",
      "Epoch 00046: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.7711 - val_loss: 2.3137\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7856\n",
      "Epoch 00047: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.7856 - val_loss: 2.3171\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7438\n",
      "Epoch 00048: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.7438 - val_loss: 2.2840\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7269\n",
      "Epoch 00049: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.7269 - val_loss: 2.3242\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7438\n",
      "Epoch 00050: val_loss did not improve from 2.21673\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.7438 - val_loss: 2.2852\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.final'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history=model.fit(train_X, train_y.reshape(train_y.shape[0],train_y.shape[1],1),\n",
    "                    epochs=50, batch_size=512, validation_split=0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-49-47e1185d18db>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.final')\n",
    "preds = model.predict_classes(val_X.reshape((val_X.shape[0],val_X.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.504504504504505"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((preds==val_y)*1)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 22)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
