{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"reading file content\"\"\"\n",
    "def read_text(filename):\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"separate into lines\"\"\"\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"hin.txt\")\n",
    "data = to_lines(data)\n",
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Wow!', 'वाह!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #6179147 (fastrizwaan)'],\n",
       "       ['Help!', 'बचाओ!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #459377 (minshirui)'],\n",
       "       ['Jump.', 'उछलो.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #6179121 (fastrizwaan)']],\n",
       "      dtype='<U121')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Wow!',\n",
       "  'वाह!',\n",
       "  'CC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #6179147 (fastrizwaan)'],\n",
       " ['Help!',\n",
       "  'बचाओ!',\n",
       "  'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #459377 (minshirui)'],\n",
       " ['Jump.',\n",
       "  'उछलो.',\n",
       "  'CC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #6179121 (fastrizwaan)']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[data[i][:2] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Wow!', 'वाह!'],\n",
       "       ['Help!', 'बचाओ!'],\n",
       "       ['Jump.', 'उछलो.'],\n",
       "       ['Jump.', 'कूदो.'],\n",
       "       ['Jump.', 'छलांग.'],\n",
       "       ['Hello!', 'नमस्ते।'],\n",
       "       ['Hello!', 'नमस्कार।'],\n",
       "       ['Cheers!', 'वाह-वाह!'],\n",
       "       ['Cheers!', 'चियर्स!'],\n",
       "       ['Got it?', 'समझे कि नहीं?']], dtype='<U121')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2774, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Wow!', 'Help!', 'Jump.', ...,\n",
       "       'Democracy is the worst form of government, except all the others that have been tried.',\n",
       "       'If my boy had not been killed in the traffic accident, he would be a college student now.',\n",
       "       \"When I was a kid, touching bugs didn't bother me a bit. Now I can hardly stand looking at pictures of them.\"],\n",
       "      dtype='<U121')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['वाह!', 'बचाओ!', 'उछलो.', ...,\n",
       "       'लोकतंत्र सरकार का सबसे घिनौना रूप है, अगर बाकी सारी तरह की सरकारों को अंदेखा किया जाए तो।',\n",
       "       'अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया होता, तो वह अभी कॉलेज जा रहा होता।',\n",
       "       'जब मैं बच्चा था, मुझे कीड़ों को छूने से कोई परेशानी नहीं होती थी, पर अब मैं उनकी तस्वीरें देखना भी बर्दाश्त नहीं कर सकता।'],\n",
       "      dtype='<U121')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in df[:,0]]\n",
    "df[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in df[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Wow', 'वाह'],\n",
       "       ['Help', 'बचाओ'],\n",
       "       ['Jump', 'उछलो'],\n",
       "       ['Jump', 'कूदो'],\n",
       "       ['Jump', 'छलांग'],\n",
       "       ['Hello', 'नमस्ते।'],\n",
       "       ['Hello', 'नमस्कार।'],\n",
       "       ['Cheers', 'वाहवाह'],\n",
       "       ['Cheers', 'चियर्स'],\n",
       "       ['Got it', 'समझे कि नहीं']], dtype='<U121')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[i,0] = df[i,0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['wow', 'वाह'],\n",
       "       ['help', 'बचाओ'],\n",
       "       ['jump', 'उछलो'],\n",
       "       ['jump', 'कूदो'],\n",
       "       ['jump', 'छलांग'],\n",
       "       ['hello', 'नमस्ते।'],\n",
       "       ['hello', 'नमस्कार।'],\n",
       "       ['cheers', 'वाहवाह'],\n",
       "       ['cheers', 'चियर्स'],\n",
       "       ['got it', 'समझे कि नहीं']], dtype='<U121')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "engl = []\n",
    "hindi = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in df[:,0]:\n",
    "      engl.append(len(i.split()))\n",
    "\n",
    "for i in df[:,1]:\n",
    "      hindi.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':engl, 'hin':hindi})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>hin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2774 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      eng  hin\n",
       "0       1    1\n",
       "1       1    1\n",
       "2       1    1\n",
       "3       1    1\n",
       "4       1    1\n",
       "...   ...  ...\n",
       "2769   17   16\n",
       "2770   14   13\n",
       "2771   15   18\n",
       "2772   18   17\n",
       "2773   22   25\n",
       "\n",
       "[2774 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 2370\n"
     ]
    }
   ],
   "source": [
    "eng_tokenizer = tokenization(df[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 22\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi Vocabulary Size: 2980\n"
     ]
    }
   ],
   "source": [
    "hindi_tokenizer = tokenization(df[:, 1])\n",
    "hindi_vocab_size = len(hindi_tokenizer.word_index) + 1\n",
    "\n",
    "hindi_length = 22\n",
    "print('Hindi Vocabulary Size: %d' % hindi_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,val = train_test_split(df, test_size=0.2, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['theres no use trying to persuade him',\n",
       "        'उसको मनाने की कोशिश करने में कोई फ़ायदा नहीं है।'],\n",
       "       ['i advise you not to borrow money from your friends',\n",
       "        'मेरी तुम्हारे लिए यह सलाह है कि अपने दोस्तों से पैसे उधार मत लो।'],\n",
       "       ['they live in a little village in england',\n",
       "        'वे इंग्लैंड के एक छोटे से गाँव में रहते हैं।'],\n",
       "       ...,\n",
       "       ['he is always complaining about his boss',\n",
       "        'वह हमेशा अपने बॉस की शिकायत करता रहता है।'],\n",
       "       ['because of his advice i was able to succeed',\n",
       "        'मैं उसकी सलाह की वजह से कामयाब हो गया।'],\n",
       "       ['when will you be back it all depends on the weather',\n",
       "        'कब वापस आओगे यह तो मौसम देख कर पता चलेगा।']], dtype='<U121')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "train_y = encode_sequences(hindi_tokenizer, hindi_length, train[:, 1])\n",
    "\n",
    "val_X = encode_sequences(eng_tokenizer, eng_length, val[:, 0])\n",
    "val_y = encode_sequences(hindi_tokenizer, hindi_length, val[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[661,  62, 167, ...,   0,   0,   0],\n",
       "       [  2, 801,   4, ...,   0,   0,   0],\n",
       "       [ 46,  91,   9, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  7,   5, 135, ...,   0,   0,   0],\n",
       "       [171,   8,  21, ...,   0,   0,   0],\n",
       "       [ 57,  23,   4, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  68, 2430,   13, ...,    0,    0,    0],\n",
       "       [  33,   49,   25, ...,    0,    0,    0],\n",
       "       [  93,  957,    7, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   5,  155,   34, ...,    0,    0,    0],\n",
       "       [   4,   50,  374, ...,    0,    0,    0],\n",
       "       [ 212,  133,  530, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 22)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2219, 22)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 22)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2219, 22)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(inp_vocab,out_vocab, inp_timesteps,out_timesteps,units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(inp_vocab, units, input_length=inp_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(eng_vocab_size, hindi_vocab_size, eng_length, hindi_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.4308\n",
      "Epoch 00001: val_loss improved from inf to 2.66186, saving model to model.final\n",
      "WARNING:tensorflow:From E:\\Anaconda-64\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From E:\\Anaconda-64\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 80s 20s/step - loss: 6.4308 - val_loss: 2.6619\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.5682\n",
      "Epoch 00002: val_loss improved from 2.66186 to 2.60198, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 80s 20s/step - loss: 2.5682 - val_loss: 2.6020\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.5351\n",
      "Epoch 00003: val_loss improved from 2.60198 to 2.44479, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 82s 20s/step - loss: 2.5351 - val_loss: 2.4448\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.3822\n",
      "Epoch 00004: val_loss improved from 2.44479 to 2.41660, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 79s 20s/step - loss: 2.3822 - val_loss: 2.4166\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.5033\n",
      "Epoch 00005: val_loss did not improve from 2.41660\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5033 - val_loss: 2.4422\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.3500\n",
      "Epoch 00006: val_loss improved from 2.41660 to 2.36196, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 85s 21s/step - loss: 2.3500 - val_loss: 2.3620\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2894\n",
      "Epoch 00007: val_loss improved from 2.36196 to 2.32842, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 89s 22s/step - loss: 2.2894 - val_loss: 2.3284\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1951\n",
      "Epoch 00008: val_loss did not improve from 2.32842\n",
      "4/4 [==============================] - 18s 5s/step - loss: 2.1951 - val_loss: 2.4671\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2185\n",
      "Epoch 00009: val_loss did not improve from 2.32842\n",
      "4/4 [==============================] - 21s 5s/step - loss: 2.2185 - val_loss: 2.5416\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2202\n",
      "Epoch 00010: val_loss did not improve from 2.32842\n",
      "4/4 [==============================] - 20s 5s/step - loss: 2.2202 - val_loss: 2.3925\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1704\n",
      "Epoch 00011: val_loss did not improve from 2.32842\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.1704 - val_loss: 2.3561\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1383\n",
      "Epoch 00012: val_loss did not improve from 2.32842\n",
      "4/4 [==============================] - 19s 5s/step - loss: 2.1383 - val_loss: 2.4041\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1127\n",
      "Epoch 00013: val_loss improved from 2.32842 to 2.31855, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 81s 20s/step - loss: 2.1127 - val_loss: 2.3186\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1171\n",
      "Epoch 00014: val_loss improved from 2.31855 to 2.24751, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 77s 19s/step - loss: 2.1171 - val_loss: 2.2475\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0558\n",
      "Epoch 00015: val_loss did not improve from 2.24751\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0558 - val_loss: 2.4263\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0750\n",
      "Epoch 00016: val_loss improved from 2.24751 to 2.20880, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 81s 20s/step - loss: 2.0750 - val_loss: 2.2088\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0860\n",
      "Epoch 00017: val_loss did not improve from 2.20880\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0860 - val_loss: 2.3018\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0274\n",
      "Epoch 00018: val_loss did not improve from 2.20880\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.0274 - val_loss: 2.2657\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0197\n",
      "Epoch 00019: val_loss did not improve from 2.20880\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.0197 - val_loss: 2.2786\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9978\n",
      "Epoch 00020: val_loss did not improve from 2.20880\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9978 - val_loss: 2.2848\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0069\n",
      "Epoch 00021: val_loss improved from 2.20880 to 2.20445, saving model to model.final\n",
      "INFO:tensorflow:Assets written to: model.final\\assets\n",
      "4/4 [==============================] - 79s 20s/step - loss: 2.0069 - val_loss: 2.2045\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9945\n",
      "Epoch 00022: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9945 - val_loss: 2.2441\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9549\n",
      "Epoch 00023: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9549 - val_loss: 2.2641\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9765\n",
      "Epoch 00024: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9765 - val_loss: 2.2214\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9202\n",
      "Epoch 00025: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9202 - val_loss: 2.3309\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9486\n",
      "Epoch 00026: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9486 - val_loss: 2.2759\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9434\n",
      "Epoch 00027: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9434 - val_loss: 2.2454\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9162\n",
      "Epoch 00028: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9162 - val_loss: 2.2487\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9286\n",
      "Epoch 00029: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9286 - val_loss: 2.2390\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8803\n",
      "Epoch 00030: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8803 - val_loss: 2.2274\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9126\n",
      "Epoch 00031: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9126 - val_loss: 2.2404\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8543\n",
      "Epoch 00032: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8543 - val_loss: 2.2794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8951\n",
      "Epoch 00033: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.8951 - val_loss: 2.2395\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8492\n",
      "Epoch 00034: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8492 - val_loss: 2.2997\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8598\n",
      "Epoch 00035: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8598 - val_loss: 2.2856\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8323\n",
      "Epoch 00036: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8323 - val_loss: 2.3083\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8352\n",
      "Epoch 00037: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8352 - val_loss: 2.2782\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8395\n",
      "Epoch 00038: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8395 - val_loss: 2.2950\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8031\n",
      "Epoch 00039: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.8031 - val_loss: 2.2789\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8222\n",
      "Epoch 00040: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.8222 - val_loss: 2.2952\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7911\n",
      "Epoch 00041: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.7911 - val_loss: 2.3000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7877\n",
      "Epoch 00042: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7877 - val_loss: 2.3212\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7993\n",
      "Epoch 00043: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7993 - val_loss: 2.2713\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7598\n",
      "Epoch 00044: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7598 - val_loss: 2.3483\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7690\n",
      "Epoch 00045: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7690 - val_loss: 2.2674\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7237\n",
      "Epoch 00046: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7237 - val_loss: 2.3486\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7862\n",
      "Epoch 00047: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7862 - val_loss: 2.2821\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7163\n",
      "Epoch 00048: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.7163 - val_loss: 2.3178\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7556\n",
      "Epoch 00049: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.7556 - val_loss: 2.3022\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7074\n",
      "Epoch 00050: val_loss did not improve from 2.20445\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.7074 - val_loss: 2.3028\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.final'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history=model.fit(train_X, train_y.reshape(train_y.shape[0],train_y.shape[1],1),\n",
    "                    epochs=50, batch_size=512, validation_split=0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoNklEQVR4nO3deZhU1YH38e+prav3HRqapUERkEXAFnBF3IJxiUuMJjGJThJmzGIy7zgzjpl5TTLjjPNOXl+TmWgmJhqTuA7GJWqixoBKVBTCvgiyNw1NL/S+VFfVef841QvQDQ1005eu3+d5+qnl3lt1bnXVr06dc+49xlqLiIh4l2+wCyAiIkemoBYR8TgFtYiIxymoRUQ8TkEtIuJxgYF40IKCAltSUjIQDy0iMiStWLGiylpb2NOyAQnqkpISli9fPhAPLSIyJBljdva2TE0fIiIep6AWEfE4BbWIiMcNSBu1iAwd7e3tlJWV0draOthFGRLC4TCjRo0iGAz2eRsFtYgcUVlZGZmZmZSUlGCMGezinNKstVRXV1NWVsa4ceP6vJ2aPkTkiFpbW8nPz1dI9wNjDPn5+cf860RBLSJHpZDuP8fzWnoqqH/05hbe2lw52MUQEfEUTwX1f7+1lbcV1CLSTW1tLQ899NAxb/fJT36S2tra/i/QIPBUUKeG/LS0xwa7GCLiIb0FdTQaPeJ2r776Kjk5OQNUqpPLU6M+wkE/rQpqEenm7rvvZuvWrcyYMYNgMEg4HCY3N5dNmzaxefNmrrvuOnbv3k1rayvf+ta3WLhwIdB1KovGxkauvPJKLrjgAt59912Ki4t58cUXSU1NHeQ96ztPBXWqglrE07732/VsKK/v18c8c2QW914zpdfl999/P+vWrWPVqlUsWbKEq666inXr1nUOb3v00UfJy8ujpaWFc845hxtvvJH8/PyDHmPLli089dRTPPLII3zmM5/hueee49Zbb+3X/RhIngrqcNBPS0RBLSK9mz179kFjkH/0ox/x/PPPA7B79262bNlyWFCPGzeOGTNmAHD22WezY8eOk1XcfuGpoE4Nqo1axMuOVPM9WdLT0zuvL1myhD/84Q+89957pKWlcfHFF/c4RjklJaXzut/vp6Wl5aSUtb94qjMxHPLT0h4f7GKIiIdkZmbS0NDQ47K6ujpyc3NJS0tj06ZNvP/++ye5dCeHx2rUPirqVKMWkS75+fmcf/75TJ06ldTUVIYPH965bMGCBfzkJz9h8uTJTJw4kblz5w5iSQeOx4LaT2tUQS0iB3vyySd7vD8lJYXf/e53PS7raIcuKChg3bp1nfffdddd/V6+geappo/UkDoTRUQO5amgTgmoM1FE5FCeCurUkMZRi4gcyltBHfTTHrO0xzTyQ0Skg+eCGlCtWkSkG08FdTjUEdSqUYuIdOhTUBtjcowxi4wxm4wxG40x5w5EYVSjFpETlZGRAUB5eTmf/vSne1zn4osvZvny5Ud8nAcffJDm5ubO24N52tS+1qh/CPzeWjsJOAvYOBCFCQddcTTyQ0RO1MiRI1m0aNFxb39oUA/maVOPGtTGmGzgIuDnANbaiLW2diAK01Gj1lhqEelw99138+Mf/7jz9ne/+13+5V/+hUsvvZRZs2Yxbdo0XnzxxcO227FjB1OnTgWgpaWFW265hcmTJ3P99dcfdK6PO+64g9LSUqZMmcK9994LuBM9lZeXM3/+fObPnw+406ZWVVUB8MADDzB16lSmTp3Kgw8+2Pl8kydP5qtf/SpTpkzhiiuu6LdzivTlyMRxQCXwmDHmLGAF8C1rbVP3lYwxC4GFAGPGjDmuwnQGtWrUIt70u7th39r+fcyiaXDl/b0uvvnmm/n2t7/N17/+dQCeffZZXnvtNe68806ysrKoqqpi7ty5XHvttb3OR/jwww+TlpbGxo0bWbNmDbNmzepcdt9995GXl0csFuPSSy9lzZo13HnnnTzwwAMsXryYgoKCgx5rxYoVPPbYYyxbtgxrLXPmzGHevHnk5uYO2OlU+9L0EQBmAQ9ba2cCTcDdh65krf2ptbbUWltaWFh4XIXp6ExUUItIh5kzZ7J//37Ky8tZvXo1ubm5FBUVcc899zB9+nQuu+wy9uzZQ0VFRa+P8fbbb3cG5vTp05k+fXrnsmeffZZZs2Yxc+ZM1q9fz4YNG45YnqVLl3L99deTnp5ORkYGN9xwA++88w4wcKdT7UuNugwos9YuS9xeRA9B3R86atRtCmoRbzpCzXcg3XTTTSxatIh9+/Zx880388QTT1BZWcmKFSsIBoOUlJT0eHrTo9m+fTs/+MEP+PDDD8nNzeW22247rsfpMFCnUz1qjdpauw/YbYyZmLjrUuDIXznHSU0fItKTm2++maeffppFixZx0003UVdXx7BhwwgGgyxevJidO3cecfuLLrqo88RO69atY82aNQDU19eTnp5OdnY2FRUVB53gqbfTq1544YW88MILNDc309TUxPPPP8+FF17Yj3t7uL6ePe+bwBPGmBCwDbh9IAoT7uxM1DhqEekyZcoUGhoaKC4uZsSIEXz+85/nmmuuYdq0aZSWljJp0qQjbn/HHXdw++23M3nyZCZPnszZZ58NwFlnncXMmTOZNGkSo0eP5vzzz+/cZuHChSxYsICRI0eyePHizvtnzZrFbbfdxuzZswH4yle+wsyZMwd01hhjre33By0tLbVHG6PYk7rmds76/uv809Vn8uULxh19AxEZcBs3bmTy5MmDXYwhpafX1Bizwlpb2tP6Hjsy0RVHB7yIiHTxVFCH/D58RuOoRUS681RQG2PcLC+qUYt4ykA0kSar43ktPRXUkJjlRUEt4hnhcJjq6mqFdT+w1lJdXU04HD6m7Tw1ZyJolhcRrxk1ahRlZWVUVlYOdlGGhHA4zKhRo45pG88FtWZ5EfGWYDDIuHEahTWYvNf0EdQEtyIi3XkzqFWjFhHp5LmgDof8muFFRKQbzwV1atCnNmoRkW48F9RhNX2IiBzEc0GtzkQRkYN5LqhVoxYROZjnglrjqEVEDua9oA76aY9ZojGN/BARAY8GNUBrVEEtIgIeDOpw0BVJHYoiIo4HgzpRo1Y7tYgI4MGgTg1pglsRke68F9SdE9wqqEVEwMNBraYPERHHc0EdVtOHiMhBvBfUAdWoRUS681xQqzNRRORg3gvqzs5EHfAiIgJeDmrVqEVEAA8GdTjkiqQ2ahERx3NBHfL78BkFtYhIB88FtTHGnZNaB7yIiAAeDGrQTOQiIt15Mqg1y4uISBdPBrVmeRER6eLNoA76aW3XOGoREYBAX1YyxuwAGoAYELXWlg5koTQTuYhIlz4FdcJ8a23VgJWkm5Sgj4bW6Ml4KhERz/Nw04dq1CIi0PegtsDrxpgVxpiFPa1gjFlojFlujFleWVl5QoVKDWnUh4hIh74G9QXW2lnAlcDXjTEXHbqCtfan1tpSa21pYWHhCRVKbdQiIl36FNTW2j2Jy/3A88DsgSxUWE0fIiKdjhrUxph0Y0xmx3XgCmDdQBbKjaPW8DwREejbqI/hwPPGmI71n7TW/n4gCxUO+InE4kRjcQJ+T/Z3ioicNEcNamvtNuCsk1CWTqkdpzqNxslQUItIkvNkCnbN8qJ2ahERTwZ1OKgJbkVEOngyqDsmuFVQi4h4Nag1b6KISCdPBnVYbdQiIp28HdSqUYuIeDOoU9WZKCLSyZtB3dmZqKMTRUS8GdRq+hAR6eTtoFZnooiIN4M6JeiKpRq1iIhXgzrgwxh1JoqIgEeD2hijyQNERBI8GdSQmDcxqqAWEfFsUIeDfloiGp4nIuLZoHazvKhGLSLi2aAOB30a9SEigoeDWp2JIiKOZ4M6HPSrRi0igoeDOjWoNmoREfByUKszUUQE8HJQq+lDRATwcFCH1ZkoIgJ4PKh1PmoREQ8HdWrQTyQWJxa3g10UEZFB5d2gDrmiqUNRRJKdd4Nas7yIiAAeDuqwZnkREQFOgaBW04eIJDvPBrWaPkREHO8GdUhNHyIi4OGg7mz6iGostYgkN88Gdao6E0VEgGMIamOM3xiz0hjz8kAWqENH04c6E0Uk2R1LjfpbwMaBKsihwkFXNHUmikiy61NQG2NGAVcBPxvY4nRR04eIiNPXGvWDwN8BvfbsGWMWGmOWG2OWV1ZWnnDBwhqeJyIC9CGojTFXA/uttSuOtJ619qfW2lJrbWlhYeEJFywl4MMYaFNQi0iS60uN+nzgWmPMDuBp4BJjzK8HtFSAMUaTB4iI0Iegttb+g7V2lLW2BLgF+KO19tYBLxma5UVEBDw8jho6ZnnRAS8iktwCx7KytXYJsGRAStKDcNCncdQikvQ8XaNODanpQ0TE20Ed9KtGLSJJz9NBHVZnooiIt4M6NejXkYkikvQ8HdRhNX2IiHg7qDWOWkTE60EdUtOHiIingzoc9GuGFxFJep4O6tSgn0g0TixuB7soIiKDxttBHXLFU4eiiCQzTwe1zkktInKqBLU6FEUkiXk6qDum41LTh4gks1MkqDXyQ0SSl7eDOqQ2ahERTwe1OhNFRDwf1K546kwUkWTm6aBWZ6KIiNeDWm3UIiIeD2rVqEVEvB3U6kwUEfF4UKcEfBgDrepMFJEk5umgNsYQDmjyABFJbp4OakhMHqCgFpEk5v2gDvppiegQchFJXp4P6nDQR2tUNWoRSV6eD+rUkF+diSKS1Lwf1JqJXESSnOeDOqygFpEkd2oEtZo+RCSJeT6oU4N+HUIuIkntFAlqDc8TkeTl/aDWAS8ikuSOGtTGmLAx5gNjzGpjzHpjzPdORsE6qDNRRJJdoA/rtAGXWGsbjTFBYKkx5nfW2vcHuGyAO+AlEo0Ti1v8PnMynlJExFOOWqO2TmPiZjDxZwe0VN3onNQikuz61EZtjPEbY1YB+4E3rLXLelhnoTFmuTFmeWVlZb8VULO8iEiy61NQW2tj1toZwChgtjFmag/r/NRaW2qtLS0sLOy3AoZVoxaRJHdMoz6stbXAYmDBgJSmB2r6EJFk15dRH4XGmJzE9VTgcmDTAJerU0dQ61SnIpKs+jLqYwTwuDHGjwv2Z621Lw9ssbpo3kQRSXZHDWpr7Rpg5kkoS49SQ67Sr6AWkWTl+SMTO2vUOjGTiCQpzwd1Rxt1m2Z5EZEk5f2gDqlGLSLJzftBrc5EEUlyng9qjfoQkWTn+aBOCbgiaoJbEUlW3gpqe/i5nowxmuBWRJKad4LaWvjFVfD7e6By80GLUkOa5UVEkpd3gjrSCOmF8MF/w4/PgceugrWLINqmGrWIJLW+HEJ+cqRkwmceh8b9sPLXsOIX8NyXIS2fO2MXsbb5ZuCswS6liMhJZ2wP7cInqrS01C5fvvzEHiQeh21/hOWPEdv0Ko2+LLK/9iYUnN4/hRQR8RBjzAprbWlPy7zT9HEonw9OvwxueYK/yX+IWDxO3U8/yeJlK6iobx3s0omInDTeDepuLps3j/vy/hXT1kDJK5/l6n99jvPv/yPffGolL67aM9jF6xKPwbrn4NkvQfXWwS6NiAwR3m366EFkx3v4f30DdeFi/m34D3hnd4x99a3cdcUZfOOSCX16jIbWdjLDwf4tWDwOG16At/4dKjcBBjKL4LZXIP+0/n0uERmSTs2mjx6ESs7F/7mnyGvZyX+0fp8//fU53DCzmB+8vplH3t52xG2ttTy6dDszvv8G9764jn75gorHYf3z8PB5sOh2d9+nH4O/WgqxCPziatWsReSEnVJBDcD4i+Gmx6F8Ff5nPsf/+dQErpo+gvte3cjj7+7ocZO2aIy/XbSG77+8gbF5aTz+3k7ue2XjiYX17g/hJ+fD/9wGNg6ffhTueBem3gBFU+FLv4VYGzx+DdQc+UtERORIvDM871hM+iRc/9/wm68S+PV1/OiMK5lQn8YPX6on6PfxuTljOlfdX9/KX//ybVr3rOORKREuG97Mzyonc9/S7YSDfu76xMRjf/6P34RnboX0Arjx5zDlevD5D15n+BT44ksuqH9xNdz2MuSNP8EdF5FkdEq1UR9m1ZOw5N+gdlfnXftsLnb4dEaUTKS+fDPNZesooqrbRgawrM+6kDsrr+W6y+bzzUv71r4NwPoX4LmvQOEk+MJvIGPYkdfftxYevxaCaYmwHncse9g/mqrgmS/AjM/BrC+c/OcXkaM6Uhv1qR3UHVoOwL61tO9ZzfvvLqGw8SPGBarZFitkp7+EmaXnMfz0mTDsTEjNhWUPY5f+EBtp4unoPOLz7ubWy+ce/Xn+/Cv47Z0wajZ87hlIzelb+fatdTXrUAZc8c8w9vzeA95aqFgHG16Cjb8FLFzyTzDpKjCmr69Il2gEfvkp2PUuBMLwl+9A4RnH/jgiMqCGflB30xKJ8aXHPuCD7TXMGZfHQ5+fRX5GyuErNlURf+s/iH/wM9qtjy3jv8j06++CrBE9P/C7/wWvfwdOuxRu/hWE0o+tYHvXwK9vhKb97nbBGTD2PBh7gbts2AsbXnThfGA7GJ8L9KZKN5Jk3EWw4H7XpNJX1sJL33BHei64341KyRsPf/E6+E/NVi+RoSqpghqgqS3KW5srufzM4QT9R+4vba/axp9/cRdzGt8EIJo5isDYuTB6Doye7YLxrX+Ht/8DzrwObngEAqHjK1isHfauhh1LYeefYNf70FbftdwXgHHz4MxrYeJVkFEIsSgsfxQW3+fWLf0LuPgeSM8/+vO992N47R646G/hkn+Edb9xo1Pm/yPM+9vj2weRwdZUBR/+DNLyYdaXjv55tNYNn921DKbfBMVnn5RiHqukC+pj1RaN8eCTLxHZ/CazzGbOC31MbqzaLfSnuNEbM78A1/zw8E7DExGPuWaRXe9DOBsmLnBNMz1prnHt8R/+HFIyYN7dLrSD4Z7X3/IGPPkZ12Ry0y/dkZ4Ai/7C1dy/+kcYMcTPnVK1BV75X+6DetZn3RdgSuZgl0rADW1t2As1W92oqKYqN6Kr+Ozem/haauHd/4T3H4b2Jndfbglceq/r0O9pu53vwuv/BHuWu1+pNg5jzoVzvwETr+z981y3B8o+BH/IHRORNdKdNK4/P/+HUFD30Z7aFp75YBdPfbCLYGM5l2Xu4MbCck47YwoZ8755fG3E/W3/Rvj9P8C2xZAxHM79ugvs7gFU+RH87DLIGQtffu3gZprmGnhorquNLFwCgR6aheIxWPEYlK2AUaWuCaZwojf2v69WPQWv/I3bv9QcFwbBNJh8jQvtcRcN6IfupNi/EVY/5X6pZQxP/A1zwZIxHNqb3ZdV9cdQtbnrenszFE2HkTO7/nLGdP1/rXXvk/oyF1iNFe41zBzpAiuzCPyHHDTW1gD15VC/x122HIBoK0TboL3FXUZb3f01293/I9py+D5lj4Ep17ngHTnTlamtEZb9BN79EbTWuWUX3wO1O+GNe2H/ehg5y/X/lFzgHqdyM/zhXvjoVVfuS74Dk652AxDefxjqdrlmwLlfc53sDftcqO981/3ard15eNmM3+175ghXWbIWsF3n0bfWvU63PHFc/04F9TFqj8X5w4YKfr1sJ3/6uJqMlAB/v2Ain58zFp/PA2FlrWs+eecHsG0JhHNgzl/BnL90yx+5BCJNrtacM/rw7Te/Dk/eBOd/Gy7/3sHL9q6B334Lyv8MKdnQVufuT8t3NZGSC9yHvK3Btbc3VUJjpbtsrnIfqvYWV+OJNCc+pC0uGC+9F0bOOP79jra5D2p6Ye9fGm2N8OpdLsDGnu+aqrJGwu4PYPWTsO55t09ZxS60i892H/K88V2/Ok62lgPu/7ntLRdgo+fAafNduQ7tS2hvhY0vwfLHXAexL+hqfR01zN6kZEH+6a5vJJDimuAq1kO83S1PzYOCCe7/WF/uQrVXxn0RZI1w5anfc3AT3qHrBlNdR3Yg7CoUeePdEbt54yDvNHc7JRM2v+YOINv6R1eunLHuddj0iivXGQtg/ndgxPSuh4/HYPXTrmmwfo9bJ7PIdfwH0+DCv4Y5d0AorWubWNS9hu/9F+xZ4QLYJk6jnJbv+ozGnAdj5rjyN+x1r0nDXqjfCw3l7n3dsX/GdF2m5iqoB8PH+xv47ksbWPpxFbPG5HD/jdM5Y7iHfj6XrYB3/i989AoE0yG7GA7scIevj57d+3YvfdN1Mt7+e/eGjDS5ppX3HoK0PPjEv8G0T7uOze41jQM7Dn+sUKYbU55e4Ea2hNLdhySYmqjNGxecLTUw7SbXXp5b0nvZDuxwH6Ca7e56x19dGWAhdxxMuBwmXOG+OIKpbrt9a+F/bne1xnl/D/P+7vBac3uLq2WtesqFY0etLiUbRp7lwrFwovuJHIu4D3Us4oIjHnOBEs5xTVWpictwjnvNevp1cqhY1L0OFeth+1sunPeucs8XTHPhVLnJ7WdKNoy70DUJFE2HTb+FlU+47fPGw9m3w4zPu/6KtkZX823cn7iscAFeMAHyJ7ia9qFfbtE2V47yle6vZrvrF8kqhuxRictiF8qtdYkac3lXzblhrwvfrGL3ZdixftZIF/zBVNfvcqy/xFoOuHBe/7yriIw9Dy753zD6nN63aW9xte53HnC/GEq/7P7/6QW9b2Mt7F7mRlgVTHDPU3DGoP1yVFCfIGstz6/cwz+/vIHGtih3zDuNr80/vXPi3e5qmiLsqmmmPRYnFrddf9aChWmjsinoaRTKiarYAEsfcO3P1/4nnHXLkddva3CHvhu/q1W/9o/u5+CsL8Jl33PB05O6PVC50dUc0gshreDg2kpvWuvgTz90XwTxKJzzFbjoLvdBaq6B7W+7D+W2Je7LoUP6MFfzyi1xAZ2SCTvecQEXbXFBUXKhC9cPHnHlvuERF3BHE4u6fSlfCXv+7H5FVKx35TseoQz3/GkFrmaWlu8C/qBfHdVA4jPnC0BxqQvi8fPc9UDIvR4dr8W2xV3HCfgCrs/h7Ntdp/Ng/QI4meLxY9vP1jo3JDWjcODKNEAU1P2kurGN+17ZyG9W7mF8YTrfmH86NU0RPt7fyNbKRrZWNlHTFDniY/gMnHtaPldNG8mCqUXkpR/nCJLexGN9b3vdsdRNfwZQMBGuedDVKgZS/V5Xc1/5K/cLIP809zMc62rmHTXIMee6Zb0Ng2xvhZ1LYcsfYMvrrlNqwhVw3cNHrkUdTcdPeX+wq1nBH3CXxudqrq21rmOrtbbressBF8Ld/5qq3bbphV1/GcPcZW4JjJl79M5Na11zyN5Vrikns+j49008TUHdz97eXMl3XljL7hr3szk/PcRphRmcNiyd0wozKMlPJxz04/OB3xj8PoPPZ4jGLG9vruTlNeXsqG7G7zOcd1o+V00bwfxJwxie1csIjoH04c/dNGhz7jj+YYfHo/IjF9gNFa42OX4+FM86vJOqr5prXC3/VOrwFOlGQT0AWiIxNlc0MCYvjdxjrBVba9mwt55X1uzl5TV72VXTDMCI7DAzx+QwY3QOM8fkMnVkNqmhU3xkgoj0iYLaw6y1rC+v54PtNazcXcuq3Qc6a+p+n2HCsAwmFWVyRlEmE4dncsbwTEblpmJUcxQZUo4U1DqOeJAZY5hanM3U4uzO+6oa21i1q5aVuw90hvgLq8o7l6eH/IzOSyMWt7RF47RFY0SicdqicQAumzycL5w7ltKxuQp0kSFANepTRH1rO1sqGvhoXyObKxooO9BCKGAI+X2kBPyEAj5CAR9NbVFeWbuXhtYok4oyuXXuWK6bWUxGyuHfyS2RGGUHmtnf0MaB5ggHmtupbUpcNkdITwlww6xiZozOUeCLDDA1fSSZ5kiUl1aV88v3drJhbz0ZKQE+NWMkOWlBdte0sPtAM7trWqhqbOtx+/SQn5y0EDVNEVraY0wqyuSzs8dw3YxistP6eRozEQFOMKiNMaOBXwLDcQNAf2qt/eGRtlFQe4O1lpW7a/n1ezt5ee1eYnHLyJwwo3PT3F9eKqPz0hieFSY3LURuWpDstCApAdeB2dDazkury3n6g92s3VNHSsDHVdNGcN3MYoqyw6SnBMgIBUhP8RM4ysmvROTITjSoRwAjrLV/NsZkAiuA66y1G3rbRkHtPa3tMQI+c9yBum5PHU9/uIsXV5bT0Hb4ASHhoI+MlCCjclMZX5DOuIJ0xhW6y5L8dPw+Q31rOw2tUepb2qlvjdLQ2o7BkJ8RIj89RF56iJy0EH4vHKYvcpL1a9OHMeZF4L+stW/0to6CeuhqjkRZvuMA9a3tNLVFaWiN0tQWoyniAnhXTTPbq5rYW3ekc0X0zmcgNy1EcW4q547P54IJBZxTktfjUaAdrLU0tkXJSAmoLV1OWf0W1MaYEuBtYKq1tv6QZQuBhQBjxow5e+fOHs4+JUmjORJlR1UzO6qb2F7lThiUlRokKxwgKxwkKzVAZjhILG6paYpQ3RShprGN6sT1j/c3snLXAdpjllDAR+nYXC6YUMCMUTlUNraxrbKJHdVN7KhqYltVEw2tUc4YnsFNZ4/mupnFFGYOwGH6IgOoX4LaGJMBvAXcZ639zZHWVY1a+kNzJMoH22tYuqWKpR9XsWlfQ+cyY2BkdirjC13TyrDMFP740X5W7qrF7zPMnziMm0pHccmkYQT9PmqbI6wvr2dDeT3ry+tYX15PTVOElICPcNBPStBPOOgjHPCTlRpg4vBMJo/IYvKILMbkpfV61sRY3NLYGiUrVbV5OTEnHNTGmCDwMvCatfaBo62voJaBUNnQxsa99YzIDjM6L63H5pCP9zfwPyvK+M2f91DZ0EZ+eohw0M+e2q5zH4/IDjNlZBbDs8K0ReO0tsdobXfj0VsiMWqaIuyobiKe+Gikh/xMLMrktMIMmttjVDe2uV8BjREONEeIWyjOSWXB1CI+Oa2ImaNzew32jjHycWuZN7Gws+NW5EQ7Ew3wOFBjrf12X55QQS2DLRqL8/aWSl5YWY4FpozMYsrILM4ckdXzHJqH6DhFwMa99Ym/BrZXN5GZEiA/w3V85mekkJ8eIiMlwAfba3hnSxWRWJzhWSl8YkoRC6YWkRr0s3JX7WFHnQLkpYe4YWYxt8wezenDDj85k7WWbVVNvLO5ktVldUwtzuaKM4czOq8PZyuUU86JBvUFwDvAWiCeuPsea+2rvW2joJZkVN/azuJN+3l17V6WfFTZeaQodJ3HZeboXGaMyaGpLcozH+7mjQ0VROOW0rG53DJ7DBdOKGDFzgO8s6WStzdXdf4SyEsPdZ6ZcVJRJlecOZzLzyxianFWZ5OLtZbW9ji1LREONLWTkRJgdJ5ON3Cq0AEvIidZU1uUd7ZUYi3MHJNLUXbPZ0asamzjuRVlPPPhbrZVdc3SkpkS4LzT87lwQiEXTShkTH4aO6ubeGNDBa9vqGD5jhriFoqywmSnBjnQHKG2pZ1Ity+Hjsdxbe2ZnDnStbmPzk0jZi3RmKU9Ficat0RjcSKxOJFovPN0BB2X0XicSUVZTBiW4Y0ZjoYoBbWIx1lr+WB7Dat213L22FxmjM454pj3mqYIb26sYMlHlUTjcXJSQ+SkBclJc5fZqUHqWtrZUF7f2XzTFImdUBlz04LMHpfH7HH5zBmXx+QRWfh9hrqWdnbXNFOWOOK17EAzAb+P6aOyOWtUDmPz01Sr7wMFtUiSi8ctu2qa2bi3nr11rQT8hoDPR8BvCCauB/0+UgLuLxToOocMwJqyWpZtr2HZ9urOdvbMcAAD1LcefABUZkqASKzrJGHZqcHO0D6jKJNwwEcw4CPkd88Z9Bt8xlDb0s6Bpgg1Ta6TtqYpQl1LOxOHZ3L+hAKmF2cPyBGwHWPwB5uCWkT6TXltC8u2V/PhjgP4jXGnIshNY3ReGqNyU8lOdePjN1c0srqsltW7a1ldVsfmigZi8b7ljc9ATlqI9BR/1xdDSoC5p+VzwekFnH96AYUZKdS3tlPXkjjitbWd+pZ2slKDXHB6AelHCN9INM7v1u3lV+/tZPnOA8wZl8fX5p/ORRMKBq32r6AWkUHXEomx+0AzkWic9lic9kQbeSQWJx635KQFyU1zI2qywsHO9vCapgjvbq3iTx+78fTdR870JuT3cd7p+Vw2eTiXTh7GiGw3AXJFfStPLNvFk8t2UdXYxtj8NC6bPJxX1uxlX30rU0ZmccfFp3Hl1BEHncqgPRZn9e5aln5cxXtbq0kL+VkwtYjLz+y/6fQU1CIyZOyqbubdrVU0RWLuSNfUYOfRrlnhIGUHWnhzYwVvbKxgZ7WbPWlacTZF2WEWb9pPzFrmTxzGF88dy0UTCvH5DJFonBdW7uEnb21lW1UTJflpfPnC8USicf70cRXLtlXTFIlhjHusA80Rdte04PcZ5ozL48qpRXxiShHDTmA6PQW1iCQday1bKxt5Y8N+/rCxgl01zVw3YyS3zh3L2PyeJ02OxS2vr9/HQ0u2snZPHQDjCtI5/3TX5DJ3fD45aaHOmZl+v24fr67by7bKJoyBc0ryeOIrcwgeR1u6glpE5BhYa1m3p568jBDFOalHXXfL/kZ+t3Yfe+tauP/G6cf1nJqKS0TkGBhjmDYq++grJtY9IzGf6UDR2d5FRDxOQS0i4nEKahERj1NQi4h4nIJaRMTjFNQiIh6noBYR8TgFtYiIxw3IkYnGmErgeKchLwCq+rE4pwrtd3LRfieXvuz3WGttYU8LBiSoT4QxZnlvh1EOZdrv5KL9Ti4nut9q+hAR8TgFtYiIx3kxqH862AUYJNrv5KL9Ti4ntN+ea6MWEZGDebFGLSIi3SioRUQ8zjNBbYxZYIz5yBjzsTHm7sEuz0AyxjxqjNlvjFnX7b48Y8wbxpgticvcwSxjfzPGjDbGLDbGbDDGrDfGfCtx/5DebwBjTNgY84ExZnVi37+XuH+cMWZZ4j3/jDGmf2ZJ9RBjjN8Ys9IY83Li9pDfZwBjzA5jzFpjzCpjzPLEfcf9XvdEUBtj/MCPgSuBM4HPGmPOHNxSDahfAAsOue9u4E1r7QTgzcTtoSQK/I219kxgLvD1xP94qO83QBtwibX2LGAGsMAYMxf4d+D/WWtPBw4AXx68Ig6YbwEbu91Ohn3uMN9aO6Pb+Onjfq97IqiB2cDH1tpt1toI8DTwqUEu04Cx1r4N1Bxy96eAxxPXHweuO5llGmjW2r3W2j8nrjfgPrzFDPH9BrBOY+JmMPFngUuARYn7h9y+G2NGAVcBP0vcNgzxfT6K436veyWoi4Hd3W6XJe5LJsOttXsT1/cBwwezMAPJGFMCzASWkST7nWgCWAXsB94AtgK11tpoYpWh+J5/EPg7IJ64nc/Q3+cOFnjdGLPCGLMwcd9xv9c1ua0HWWutMWZIjps0xmQAzwHfttbWu0qWM5T321obA2YYY3KA54FJg1uigWWMuRrYb61dYYy5eJCLMxgusNbuMcYMA94wxmzqvvBY3+teqVHvAUZ3uz0qcV8yqTDGjABIXO4f5PL0O2NMEBfST1hrf5O4e8jvd3fW2lpgMXAukGOM6agsDbX3/PnAtcaYHbimzEuAHzK097mTtXZP4nI/7ot5NifwXvdKUH8ITEj0CIeAW4CXBrlMJ9tLwJcS178EvDiIZel3ifbJnwMbrbUPdFs0pPcbwBhTmKhJY4xJBS7HtdEvBj6dWG1I7bu19h+staOstSW4z/MfrbWfZwjvcwdjTLoxJrPjOnAFsI4TeK975shEY8wncW1afuBRa+19g1uigWOMeQq4GHfqwwrgXuAF4FlgDO4UsZ+x1h7a4XjKMsZcALwDrKWrzfIeXDv1kN1vAGPMdFznkR9XOXrWWvt9Y8x4XG0zD1gJ3GqtbRu8kg6MRNPHXdbaq5NhnxP7+HziZgB40lp7nzEmn+N8r3smqEVEpGdeafoQEZFeKKhFRDxOQS0i4nEKahERj1NQi4h4nIJaRMTjFNQiIh73/wEYriF+KzPhHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-47e1185d18db>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.final')\n",
    "preds = model.predict_classes(val_X.reshape((val_X.shape[0],val_X.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 22)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future scope "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The words are repeating(for english)\n",
    "- Improve accuacy of LSTM\n",
    "- removing stop words, Tf-Idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
